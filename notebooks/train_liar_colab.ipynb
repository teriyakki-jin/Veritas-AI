{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# LIAR Baseline Training v2 (6-class DistilBERT)\n**Dataset:** LIAR (10,269 train / 1,284 valid / 1,283 test)\n**Task:** 6-class political claim classification\n**Labels:** pants-fire, false, barely-true, half-true, mostly-true, true\n\n### v2 개선사항\n- metadata(speaker, subject, context) 활용하여 입력 강화\n- learning rate scheduler 개선 (cosine)\n- epoch 5로 증가 + early stopping\n- 클래스 불균형 대응 (label smoothing)\n\n> Runtime → GPU (T4) 설정 필수"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "!pip install -q transformers datasets accelerate scikit-learn safetensors"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "PROJECT_DIR = '/content/drive/MyDrive/Fakenews-detect'\n",
    "os.makedirs(f'{PROJECT_DIR}/models/liar_baseline', exist_ok=True)\n",
    "os.makedirs(f'{PROJECT_DIR}/data/liar', exist_ok=True)\n",
    "print('Project dir:', PROJECT_DIR)\n",
    "print('Files in data/liar:', os.listdir(f'{PROJECT_DIR}/data/liar') if os.path.exists(f'{PROJECT_DIR}/data/liar') else 'NOT FOUND')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Upload Data\n",
    "`data/liar/train.jsonl`, `valid.jsonl`, `test.jsonl`을 Google Drive의 `Fakenews-detect/data/liar/`에 업로드하세요.\n",
    "\n",
    "또는 아래 셀로 직접 업로드:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option A: 로컬에서 직접 업로드\n",
    "from google.colab import files\n",
    "import shutil\n",
    "\n",
    "data_dir = f'{PROJECT_DIR}/data/liar'\n",
    "needed = ['train.jsonl', 'valid.jsonl', 'test.jsonl']\n",
    "missing = [f for f in needed if not os.path.exists(os.path.join(data_dir, f))]\n",
    "\n",
    "if missing:\n",
    "    print(f'Missing files: {missing}')\n",
    "    print('Upload them now:')\n",
    "    uploaded = files.upload()\n",
    "    for fname, content in uploaded.items():\n",
    "        dest = os.path.join(data_dir, fname)\n",
    "        with open(dest, 'wb') as f:\n",
    "            f.write(content)\n",
    "        print(f'  Saved: {dest}')\n",
    "else:\n",
    "    print('All data files present!')\n",
    "\n",
    "for f in needed:\n",
    "    p = os.path.join(data_dir, f)\n",
    "    if os.path.exists(p):\n",
    "        with open(p, 'r') as fh:\n",
    "            n = sum(1 for _ in fh)\n",
    "        print(f'  {f}: {n:,} samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset & Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import torch\nimport json\nimport ast\nimport numpy as np\nfrom torch.utils.data import Dataset\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, EarlyStoppingCallback\nfrom sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n\nLABEL_NAMES = ['pants-fire', 'false', 'barely-true', 'half-true', 'mostly-true', 'true']\nLABEL_MAP = {name: i for i, name in enumerate(LABEL_NAMES)}\n\nclass LIARDataset(Dataset):\n    def __init__(self, data_path, tokenizer, max_len=128, use_metadata=True):\n        self.samples = []\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n        self.use_metadata = use_metadata\n        with open(data_path, 'r', encoding='utf-8') as f:\n            for line in f:\n                self.samples.append(json.loads(line))\n        print(f'Loaded {len(self.samples)} samples from {data_path}')\n\n        # Label distribution\n        from collections import Counter\n        dist = Counter(s.get('label_class', '?') for s in self.samples)\n        print(f'Label distribution: {dict(dist)}')\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        item = self.samples[idx]\n        claim = str(item['text'])\n\n        # v2: metadata 활용 (speaker, subject, context)\n        if self.use_metadata:\n            meta = item.get('metadata', '{}')\n            if isinstance(meta, str):\n                try:\n                    meta = ast.literal_eval(meta)\n                except:\n                    meta = {}\n            speaker = meta.get('speaker', '')\n            subject = meta.get('subject', '')\n            context = meta.get('context', '')\n\n            parts = [claim]\n            if speaker:\n                parts.append(f'Speaker: {speaker}')\n            if subject:\n                parts.append(f'Subject: {subject}')\n            if context:\n                parts.append(f'Context: {context}')\n            text = ' [SEP] '.join(parts)\n        else:\n            text = claim\n\n        label_str = item.get('label_class', 'false')\n        label_id = LABEL_MAP.get(label_str, 1)\n\n        encoding = self.tokenizer(\n            text, max_length=self.max_len, padding='max_length',\n            truncation=True, return_tensors='pt'\n        )\n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'labels': torch.tensor(label_id, dtype=torch.long)\n        }\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    preds = np.argmax(logits, axis=-1)\n    return {\n        'accuracy': accuracy_score(labels, preds),\n        'f1_macro': f1_score(labels, preds, average='macro')\n    }\n\nprint('Device:', 'cuda' if torch.cuda.is_available() else 'cpu')\nif torch.cuda.is_available():\n    print('GPU:', torch.cuda.get_device_name(0))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "MODEL_NAME = 'distilbert-base-uncased'\nDATA_DIR = f'{PROJECT_DIR}/data/liar'\nOUTPUT_DIR = f'{PROJECT_DIR}/models/liar_baseline'\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\nmodel = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=6)\n\ntrain_dataset = LIARDataset(f'{DATA_DIR}/train.jsonl', tokenizer, max_len=192, use_metadata=True)\nvalid_dataset = LIARDataset(f'{DATA_DIR}/valid.jsonl', tokenizer, max_len=192, use_metadata=True)\n\ntraining_args = TrainingArguments(\n    output_dir=OUTPUT_DIR,\n    num_train_epochs=5,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=64,\n    warmup_ratio=0.1,\n    weight_decay=0.01,\n    learning_rate=3e-5,\n    lr_scheduler_type='cosine',\n    label_smoothing_factor=0.1,\n    logging_steps=50,\n    eval_strategy='epoch',\n    save_strategy='epoch',\n    load_best_model_at_end=True,\n    metric_for_best_model='f1_macro',\n    greater_is_better=True,\n    fp16=torch.cuda.is_available(),\n    report_to='none',\n    save_total_limit=2,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=valid_dataset,\n    compute_metrics=compute_metrics,\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n)\n\nprint(f'Training: {len(train_dataset):,} samples, 5 epochs (with early stopping)')\nprint(f'v2 improvements: metadata input, cosine LR, label smoothing 0.1')\ntrainer.train()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "test_dataset = LIARDataset(f'{DATA_DIR}/test.jsonl', tokenizer, max_len=192, use_metadata=True)\nresults = trainer.evaluate(test_dataset)\nprint('Test Results:', results)\n\n# Detailed report\npreds_output = trainer.predict(test_dataset)\npreds = np.argmax(preds_output.predictions, axis=-1)\nlabels = preds_output.label_ids\n\nprint('\\n=== Classification Report ===')\nprint(classification_report(labels, preds, target_names=LABEL_NAMES))\n\ncm = confusion_matrix(labels, preds)\nprint('=== Confusion Matrix ===')\nprint(cm)\n\n# Visualize confusion matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfig, ax = plt.subplots(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n            xticklabels=LABEL_NAMES, yticklabels=LABEL_NAMES, ax=ax)\nax.set_xlabel('Predicted')\nax.set_ylabel('True')\nax.set_title(f'LIAR Test - Acc: {results[\"eval_accuracy\"]:.3f} / F1: {results[\"eval_f1_macro\"]:.3f}')\nplt.tight_layout()\nplt.savefig(f'{OUTPUT_DIR}/confusion_matrix.png', dpi=150)\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model\n",
    "model.save_pretrained(OUTPUT_DIR)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR)\n",
    "\n",
    "# Save label map\n",
    "with open(f'{OUTPUT_DIR}/label_map.json', 'w') as f:\n",
    "    json.dump(LABEL_MAP, f)\n",
    "\n",
    "# Save test results\n",
    "with open(f'{OUTPUT_DIR}/test_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f'Model saved to {OUTPUT_DIR}')\n",
    "print('Files:', os.listdir(OUTPUT_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Download Model (Optional)\n",
    "Google Drive에 이미 저장되어 있으므로, 로컬로 복사하면 됩니다.\n",
    "\n",
    "또는 zip으로 다운로드:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd \"{OUTPUT_DIR}\" && zip -r /content/liar_baseline.zip config.json model.safetensors tokenizer.json tokenizer_config.json special_tokens_map.json vocab.txt label_map.json test_results.json 2>/dev/null || echo 'Some files may not exist yet'\n",
    "from google.colab import files\n",
    "files.download('/content/liar_baseline.zip')"
   ]
  }
 ]
}